{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZWacIeiFW47EVu6AoUs7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skystapper/ooba-sillytavern-chat-history-convert/blob/main/ooba-to-sillytavern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **A simple Chat History Converter ðŸš€**\n",
        "\n",
        "This interactive Colab notebook is your go-to tool for converting chat histories between oobabooga TGW UI's  .json format and sillytavern's .jsonl format . An effort to convert my too lengthy Oobabooga AI chat history into a structure compatible with Sillytavern and vice-versa because I couldn't find any tool to do that properly\n",
        "\n",
        "\n",
        "The fist python cell converts oobabooga's .json format in sillytavern's .jsonl format\n",
        "\n",
        "Similarly the second cell does the reverse and converts the sillytavern's .jsonl format in oobabooga's .json format\n",
        "\n",
        "\n",
        "### **How to Use:**\n",
        "\n",
        "1. **Enter Your Details:**\n",
        "    - Provide the character names in your chat history.\n",
        "    - Specify the input file path or choose to upload it during runtime.\n",
        "    - Set your desired output file name.\n",
        "\n",
        "2. **Run the Code Cell:**\n",
        "    - Execute code cell by pressing Shift + Enter or just clicking on that play button thing.\n",
        "    - Follow the prompts to upload files if needed.\n",
        "\n",
        "3. **Download Your Output:**\n",
        "    - Once the conversion is complete, click the \"Download Output File\" button to get your final result.\n",
        "\n",
        "4. **Explore and Share:**\n",
        "    - Your converted chat history is ready for use! Explore the structure or share it as needed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You are free to edit the code structure of this notebook if you need extra things in your chat history, I've kept it simple just as per my need ðŸŒŸ\n",
        "\n",
        "**Note: As per my knowledge, oobabooga's TGW UI does not support the group chat so please do not try to convert the chat history of your SillyTavern AI's group chat.**"
      ],
      "metadata": {
        "id": "eulPJMYTbBWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# @title **Oobabooga To SillyTavern chat history conversion**\n",
        "# @markdown Please enter the required details.\n",
        "\n",
        "# @markdown **Character Names**\n",
        "user_name = \"Your name in the chat history\"  # @param {type: \"string\"}\n",
        "ai_name = \"AI character's name in the chat history\"  # @param {type: \"string\"}\n",
        "\n",
        "# @markdown **Input File:** Fill thise field only if you have already uploaded the file in the colab storage, else leave it blank - you will be asked to choose file during runtime if the file is not found in your specified path.\n",
        "upload_input_file = False\n",
        "input_file_path = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if not upload_input_file:\n",
        "    try:\n",
        "        with open(input_file_path, 'r'):\n",
        "            pass\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. You will be prompted to upload the file during runtime.\")\n",
        "        uploaded = files.upload()\n",
        "        input_file_path = list(uploaded.keys())[0]\n",
        "\n",
        "# @markdown **Output File Name**\n",
        "output_file_name = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "intermediate_output_file_name = \"intermediate_output\"\n",
        "\n",
        "# the first line with necessary metadata\n",
        "inserted_line = {\n",
        "    \"user_name\": user_name,\n",
        "    \"character_name\": ai_name,\n",
        "    \"create_date\": datetime.now().strftime(\"%Y-%m-%d@%Hh%Mm%Ss\"),\n",
        "    \"chat_metadata\": {\n",
        "        \"note_prompt\": \"\",\n",
        "        \"note_interval\": 1,\n",
        "        \"note_position\": 1,\n",
        "        \"note_depth\": 4\n",
        "    }\n",
        "}\n",
        "\n",
        "# Part 1: Extracts the chat from the visible section of your ooba chat history and stores it in another JSON file\n",
        "def extract_visible_chat(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n",
        "        data = json.load(input_file)\n",
        "        visible_data = data.get('visible', [])\n",
        "        json.dump(visible_data, output_file)\n",
        "\n",
        "# Part 2: Reads the generated JSON file and converts it into a format that matches the structure of Sillytavern chat history\n",
        "def generate_message(name, is_user, message, extra=None):\n",
        "    if not message.strip():\n",
        "        return None  # Skip entries with empty messages\n",
        "\n",
        "    current_time = datetime.now().strftime(\"%B %d, %Y %I:%M%p\")\n",
        "    output = {\n",
        "        \"name\": name,\n",
        "        \"is_user\": is_user,\n",
        "        \"send_date\": current_time,\n",
        "        \"mes\": message,\n",
        "        \"extra\": extra if extra else {}\n",
        "    }\n",
        "    if is_user:\n",
        "        output[\"force_avatar\"] = \"User Avatars/user-default.png\"\n",
        "    return json.dumps(output, indent=4)\n",
        "\n",
        "def process_input_file(input_messages, output_file_path, user_name, ai_name):\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for messages in input_messages:\n",
        "            user_message = messages[0]\n",
        "            ai_message = messages[1]\n",
        "\n",
        "            user_output = generate_message(user_name, True, user_message, {})\n",
        "            ai_output = generate_message(ai_name, False, ai_message, {\n",
        "                \"gen_started\": \"2023-11-09T06:12:56.823Z\",\n",
        "                \"gen_finished\": \"2023-11-09T06:13:23.457Z\",\n",
        "                \"swipe_id\": 0,\n",
        "                \"swipes\": [ai_message],\n",
        "                \"swipe_info\": [\n",
        "                    {\n",
        "                        \"send_date\": \"November 9, 2023 11:43am\",\n",
        "                        \"gen_started\": \"2023-11-09T06:12:56.823Z\",\n",
        "                        \"gen_finished\": \"2023-11-09T06:13:23.457Z\",\n",
        "                        \"extra\": {\n",
        "                            \"api\": \"textgenerationwebui\",\n",
        "                            \"model\": \"TheBloke_echidna-tiefigther-25-GPTQ\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            })\n",
        "\n",
        "            if user_output:\n",
        "                output_file.write(user_output + '\\n\\n')\n",
        "            if ai_output:\n",
        "                output_file.write(ai_output + '\\n\\n')\n",
        "\n",
        "# Part 3: Generates a final output file with .jsonl extension which can be used in sillytavern\n",
        "def convert_json_to_jsonl(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
        "        data = \"\"\n",
        "        for line in infile:\n",
        "            data += line.strip()\n",
        "            try:\n",
        "                json_data = json.loads(data)\n",
        "                formatted_json = json.dumps(json_data, separators=(',', ':')) + '\\n'\n",
        "                outfile.write(formatted_json)\n",
        "                data = \"\"\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "# Modification Part: Modifies the first line of the generated .jsonl file\n",
        "def modify_first_line(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    if lines:\n",
        "        first_line = json.loads(lines[0])\n",
        "        first_line['is_system'] = False\n",
        "        first_line['send_date'] = \"November 9, 2023 11:40am\"\n",
        "        first_line['extra'] = {}\n",
        "        first_line = {k: first_line[k] for k in ['name', 'is_user', 'is_system', 'send_date', 'mes', 'extra']}\n",
        "\n",
        "        lines[0] = json.dumps(first_line) + '\\n'\n",
        "\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.writelines(lines)\n",
        "\n",
        "# Process the input file\n",
        "extract_visible_chat(input_file_path, '/content/pre-intermediate-output.json')\n",
        "input_messages = json.load(open('/content/pre-intermediate-output.json', 'r'))\n",
        "intermediate_output_file_path = f\"/content/{intermediate_output_file_name}.jsonl\"\n",
        "process_input_file(input_messages, '/content/pre-intermediate-output.json', user_name, ai_name)\n",
        "convert_json_to_jsonl('/content/pre-intermediate-output.json', intermediate_output_file_path)\n",
        "modify_first_line(intermediate_output_file_path)\n",
        "\n",
        "# Insert line at the beginning of the final output file\n",
        "input_file_path = intermediate_output_file_path\n",
        "output_file_path = f\"/content/{output_file_name}.jsonl\"\n",
        "\n",
        "with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
        "    # Insert the line at the beginning\n",
        "    outfile.write(json.dumps(inserted_line) + '\\n')\n",
        "\n",
        "    # Shift all lines down by one line\n",
        "    for line in infile:\n",
        "        outfile.write(line)\n",
        "\n",
        "# Button to trigger download\n",
        "download_button = widgets.Button(description=\"Download Output File\")\n",
        "output_file_path_button = widgets.Output()\n",
        "\n",
        "def on_download_button_click(b):\n",
        "    with output_file_path_button:\n",
        "         files.download(output_file_path)\n",
        "\n",
        "download_button.on_click(on_download_button_click)\n",
        "display(download_button, output_file_path_button)\n"
      ],
      "metadata": {
        "id": "hSnNMnuS6Wj9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from datetime import datetime\n",
        "\n",
        "# @title **SillyTavern To Oobabooga chat history conversion**\n",
        "# @markdown Please enter the required details.\n",
        "\n",
        "# @markdown **Input File:** Fill this field only if you have already uploaded the file in the colab storage, else leave it blank - you will be asked to choose the file during runtime if the file is not found in your specified path.\n",
        "upload_input_file = False\n",
        "input_file_path = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if not upload_input_file:\n",
        "    try:\n",
        "        with open(input_file_path, 'r'):\n",
        "            pass\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. You will be prompted to upload the file during runtime.\")\n",
        "        uploaded = files.upload()\n",
        "        input_file_path = list(uploaded.keys())[0]\n",
        "\n",
        "# @markdown **Output File Name**\n",
        "final_output_file_name = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "# Read the lines from the uploaded JSONL file and skip the first line\n",
        "with open(input_file_path, 'r') as jsonl_file:\n",
        "    lines = jsonl_file.readlines()[1:]\n",
        "\n",
        "# Extract \"is_user\" and \"mes\" fields from each line and store in the intermediate output\n",
        "intermediate_output = []\n",
        "for line in lines:\n",
        "    json_data = json.loads(line)\n",
        "    is_user = json_data.get(\"is_user\", False)\n",
        "    message = json_data.get(\"mes\", \"\")\n",
        "    intermediate_output.append({\"is_user\": is_user, \"mes\": message})\n",
        "\n",
        "# Function to generate the output\n",
        "def generate_output(intermediate_output):\n",
        "    output = {\"internal\": [], \"visible\": []}\n",
        "    user_message = \"\"\n",
        "    visible_chat_added = False  # Flag to track if <|BEGIN-VISIBLE-CHAT|> has been added to the internal part\n",
        "\n",
        "    for idx, entry in enumerate(intermediate_output):\n",
        "        if entry[\"is_user\"]:\n",
        "            # Check if the previous entry was also a user message\n",
        "            if idx > 0 and intermediate_output[idx - 1][\"is_user\"]:\n",
        "                # Consecutive user messages, no character response in between\n",
        "                output[\"internal\"].append([user_message, \"\"])\n",
        "                output[\"visible\"].append([user_message, \"\"])\n",
        "            user_message = entry[\"mes\"]\n",
        "        else:\n",
        "            character_message = entry[\"mes\"]\n",
        "\n",
        "            # Add to internal part\n",
        "            if not visible_chat_added:\n",
        "                output[\"internal\"].append([\"<|BEGIN-VISIBLE-CHAT|>\", character_message])\n",
        "                visible_chat_added = True\n",
        "            else:\n",
        "                output[\"internal\"].append([user_message, character_message])\n",
        "\n",
        "            # Add to visible part\n",
        "            output[\"visible\"].append([user_message, character_message])\n",
        "\n",
        "            user_message = \"\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Generate output\n",
        "result = generate_output(intermediate_output)\n",
        "\n",
        "# Write the output to the JSON file\n",
        "final_output_file_path = f\"{final_output_file_name}.json\"\n",
        "with open(final_output_file_path, 'w') as final_output_file:\n",
        "    json.dump(result, final_output_file, indent=4)\n",
        "\n",
        "print(f\"Final output generated at: {final_output_file_path}\")\n",
        "\n",
        "# Button to trigger download\n",
        "download_button = widgets.Button(description=\"Download Final Output\")\n",
        "output_file_path_button = widgets.Output()\n",
        "\n",
        "def on_download_button_click(b):\n",
        "    with output_file_path_button:\n",
        "        files.download(final_output_file_path)\n",
        "\n",
        "download_button.on_click(on_download_button_click)\n",
        "display(download_button, output_file_path_button)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oAnG2o9xVGO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}